# LLM_Based_Text_Summarisation
In this project I have tried to fine tune T5 large language model developed by Google using PEFT technique, followed by finetuning finetuning for less toxic sequence generation using Facebook's Roberta model as reward model. 
